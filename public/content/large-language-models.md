---
title: Pieces | LLMs
path: /large-language-models
visibility: PUBLIC
status: PUBLISHED
description: Pieces software products provide user access to 54 total large language models (LLMs) from a wide variety of providers—and we’re adding more and more!
metaTitle: Pieces Supported LLMs | Cloud & Local Models
metaDescription: Explore the available cloud-based and local LLMs supported by Pieces for AI-driven development.
ogImage: "https://storage.googleapis.com/hashnode_product_documentation_assets/og_images/pieces_more/compatible-llms.png"
---

<Image src="https://storage.googleapis.com/hashnode_product_documentation_assets/standalone_single_docs/compatible_llms/compatible-llms.png" alt="" align="center" fullwidth="true" />

***

<pieces-pro-cta />

## Compatible AI Models with Pieces

Pieces utilizes cloud-hosted LLMs from providers like OpenAI, Anthropic, and Google. Local models can optionally be downloaded and served through PiecesOS and the rest of the Pieces Suite.

## Cloud-Only LLMs | Providers

[Browse the list of cloud-hosted AI models available for use](/products/large-language-models/cloud-models) with the Pieces Desktop App and several of our plugins and extensions.

***

| **Provider** | **Model Name**                 |
| ------------ | ------------------------------ |
| *OpenAI*     | GPT-X                          |
| *Anthropic*  | Claude / Sonnet / Opus / Haiku |
| *Google*     | Gemini / Pro / Flash / Chat    |

***

## Local-Only LLMs | Providers

Read [through the list of local AI models available for use](/products/large-language-models/local-models) within the Pieces Desktop App and the rest of the Pieces Suite.

***

| **Provider** | **Model Name**               |
| ------------ | ---------------------------- |
| *Google*     | Gemma / Code Gemma           |
| *IBM*        | Granite / Code / Dense / MoE |
| *Meta*       | LLaMA / CodeLLaMA            |
| *Mistral*    | Mistral / Mixtral            |
| *Microsoft*  | Phi                          |
| *Qwen*       | QwQ / Coder                  |
| *StarCoder*  | StarCoder                    |

***

### Using Local Models with Pieces

Local models can be optionally downloaded to utilize on-device generative AI features.

PiecesOS provides a seamless experience with local models, allowing you to work entirely offline with complete privacy.

Local models are automatically available once PiecesOS is installed. Download and manage them through the Pieces Copilot LLM selector in any Pieces product.

[Learn more about PiecesOS and local model architecture →](/products/core-dependencies/pieces-os#built-in-local-models)